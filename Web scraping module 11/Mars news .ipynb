{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d62b65e",
   "metadata": {},
   "source": [
    "# Mars News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f3313",
   "metadata": {},
   "source": [
    "# Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a5a03",
   "metadata": {},
   "source": [
    "# 1. Visit Site\n",
    "Use automated browsing to visit the Mars News Site. Inspect the page to identify which elements to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ac995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate browser and store url\n",
    "browser = Browser('chrome')\n",
    "url = 'https://static.bc-edx.com/data/web/mars_news/index.html'\n",
    "\n",
    "# visit site\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd851141",
   "metadata": {},
   "source": [
    "# 2. Scrape Site\n",
    "Create a BeautifulSoup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87493a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store html content\n",
    "html = browser.html\n",
    "\n",
    "# create soup\n",
    "html_soup = soup(html, 'html.parser')\n",
    "\n",
    "# locate and extract the relevant html elements\n",
    "art_list = html_soup.find_all(class_='list_text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52980cff",
   "metadata": {},
   "source": [
    "# 3. Store Results\n",
    "Extract the titles and preview text of the scraped news articles. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: title and preview.\n",
    "\n",
    "Store all the dictionaries in a Python list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5910e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dictionaries\n",
    "# each with `title` and `preview`\n",
    "articles = [{'title':art.find(class_='content_title').text,\n",
    "             'preview':art.find(class_='article_teaser_body').text\n",
    "            } for art in art_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize to confirm\n",
    "articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4663d7",
   "metadata": {},
   "source": [
    "# 4. Export to JSON\n",
    "Store the scraped data in a file (to ease sharing the data with others). To do so, export the scraped data to a JSON file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/mars_articles.json\", \"w\") as outfile:\n",
    "    json.dump(articles, outfile, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
